package MapReduce

import math.max
import java.util
import org.slf4j.Logger
import org.apache.hadoop.io.*
import Utilities.CreateLogger
import org.apache.hadoop.mapred.*
import scala.jdk.CollectionConverters.*

/** Provides the interface for the Reducer classes corresponding to Node and Edge Similarity Jobs.
 */
object Reducers:
  private val logger: Logger = CreateLogger(Reducers)

  /** Provides a class for performing the reducer function for the Node Similarity Job.
   *
   * - The NodeReducer takes as input the key value pairs generated by the Mapper and provides the
   * maximum value of the cross node pairs similarity.
   *
   * - Across the input and output key value pairs, the keys represents the node IDs while the values represents
   * the similarity.
   *
   * @param k2 : IntWritable : Represents the datatype of the key for the input data to the reducer.
   * @param v2 : DoubleWritable : Represents the datatype of the value for the input data to the reducer.
   * @param k3 : IntWritable : Represents the datatype of the key for the output data of the reducer.
   * @param v3 : DoubleWritable : Represents the datatype of the value for the output data of the reducer.
   * @return a key value pair representing the result of the Map Reduce algorithm which each key representing
   *         the node ID pf the nodes in the Perturbed Graph while the values represent the similarity of the
   *         node of the Perturbed graph with respect to the Original Graph.
   */
  class NodeReducer extends MapReduceBase with Reducer[IntWritable, DoubleWritable, IntWritable, DoubleWritable]:
    override def reduce(key: IntWritable, values: util.Iterator[DoubleWritable],
                        output: OutputCollector[IntWritable, DoubleWritable], reporter: Reporter): Unit =
      val maxSim = values.asScala.reduce((valueOne, valueTwo) =>
        new DoubleWritable(max(valueOne.get(), valueTwo.get())))
      output.collect(key, maxSim)
    end reduce
  end NodeReducer

  /** Provides a class for performing the reducer function for the Edge Similarity Job.
   *
   * - The EdgeReducer takes as input the key value pairs generated by the Mapper and provides the
   * maximum value of the cross edge pairs similarity.
   *
   * - Across the input and output key value pairs, the keys represents the "From Node Id -> To Node Id" pair
   * while the values represents aximum similarity of the edges of the Perturbed graph with
   * respect to the Original Graph.
   *
   * @param k2 : Text : Represents the datatype of the key for the input data to the reducer.
   * @param v2 : DoubleWritable : Represents the datatype of the value for the input data to the reducer.
   * @param k3 : Text : Represents the datatype of the key for the output data of the reducer.
   * @param v3 : DoubleWritable : Represents the datatype of the value for the output data of the reducer.
   * @return a key value pair representing the result of the Map Reduce algorithm which each key representing
   *         the "From Node Id -> To Node Id" string while the values represent the maximum similarity of the
   *         edges of the Perturbed graph with respect to the Original Graph.
   */
  class EdgeReducer extends MapReduceBase with Reducer[Text, DoubleWritable, Text, DoubleWritable]:
    override def reduce(key: Text, values: util.Iterator[DoubleWritable],
                        output: OutputCollector[Text, DoubleWritable], reporter: Reporter): Unit =
      val maxSim = values.asScala.reduce((valueOne, valueTwo) =>
        new DoubleWritable(max(valueOne.get(), valueTwo.get())))
      output.collect(key, maxSim)
    end reduce
  end EdgeReducer
end Reducers